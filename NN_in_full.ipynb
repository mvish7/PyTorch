{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mvish7/PyTorch/blob/master/NN_in_full.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImFsJv6_kmnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_2oVRSxlFtB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "4fb3c798-27b0-4ad7-b650-0920fef32e48"
      },
      "source": [
        "trainset=torchvision.datasets.FashionMNIST(root='./data/FashionMNIST',\n",
        "                                           train=True, \n",
        "                                           download=True,\n",
        "               transform=transforms.Compose([transforms.ToTensor()]))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/26421880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:00, 71735944.29it/s]                              \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 520314.35it/s]\n",
            "  5%|▍         | 212992/4422102 [00:00<00:02, 1945023.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ./data/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:00, 25455184.76it/s]                           \n",
            "8192it [00:00, 158012.13it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ./data/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ-2d8AklSdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Network,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "    \n",
        "    self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "    self.out = nn.Linear(in_features=60, out_features=10)\n",
        "    \n",
        "  def forward(self,t):\n",
        "    #implementing fwd pass\n",
        "    \n",
        "    # input layer\n",
        "    t=t #returning the tensor as it as, no need of processing\n",
        "    \n",
        "    # hidden layer 1 \n",
        "    t=self.conv1(t)\n",
        "    t=F.relu(t)\n",
        "    t=F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "    \n",
        "    \n",
        "    #hidden layer 2\n",
        "    t=self.conv2(t)\n",
        "    t=F.relu(t)\n",
        "    t=F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "    \n",
        "    #hidden layer 3\n",
        "    t=t.reshape(-1,12*4*4)  #doing the flattening operation before passing the tensor from conv layer to the linear layer\n",
        "    t=self.fc1(t)\n",
        "    t=F.relu(t)\n",
        "    \n",
        "    #hidden layer 4\n",
        "    t=self.fc2(t)\n",
        "    t=F.relu(t)\n",
        "    \n",
        "    #output layer\n",
        "    t=self.out(t)\n",
        "    #t=F.softmax(t, dim=1)  no need to use softmax here, coz we are using cross entropy as our loss function and it has built in softmax.\n",
        "    \n",
        "    \n",
        "    return t\n",
        "  \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcoSFR54lmQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "network=Network()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUav5z-_nbzT",
        "colab_type": "text"
      },
      "source": [
        "fetching one image from training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeCMrf0GnRmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_img=next(iter(trainset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFcaU0-hnXsj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c048bcb2-ec69-4ee3-b77e-fc57c544c8cb"
      },
      "source": [
        "image, label=sample_img\n",
        "image.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O342Qzhfno59",
        "colab_type": "text"
      },
      "source": [
        "as torch requires the ip tensor in the form of [batch_size, ip channels, W, H] we have to change the shape of this tensor by unsqueez operation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb_8JnHCngvH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c322581-2e0f-4589-c487-b618877eeb33"
      },
      "source": [
        "image.unsqueeze(0).shape #now we can send this in."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8u-fCcjn-d3",
        "colab_type": "text"
      },
      "source": [
        "let's get a rough prediction from image (forward pass)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSp-KBoEn70K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = network(image.unsqueeze(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCoR_R_YpUp0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "531241d6-954f-4279-9960-b3cfe0a7bafc"
      },
      "source": [
        "pred.shape\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaR4q6UsubBZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8bd8bb0b-1c77-4c05-d261-ee3214c076e5"
      },
      "source": [
        "pred"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0075, -0.1422, -0.1128, -0.0014,  0.0011,  0.1126,  0.0267,  0.0199,\n",
              "         -0.0983, -0.0984]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG-G0OuPudtz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c4713354-40ba-490f-8bc1-47ba89db3c9a"
      },
      "source": [
        "\n",
        "label"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1hiSJgcu9_m",
        "colab_type": "text"
      },
      "source": [
        "getting the probabilities of every prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N7-SBo7ue8p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3a09127c-2738-4e83-da8f-63d1b01b102e"
      },
      "source": [
        "F.softmax(pred, dim=1) #why dim=1? last axis of the temsor has the numbers other axes has the arrays"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1020, 0.0891, 0.0918, 0.1026, 0.1029, 0.1150, 0.1055, 0.1048, 0.0931,\n",
              "         0.0931]], grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vw1J0gfTDI8",
        "colab_type": "text"
      },
      "source": [
        "now sending batch of images to n/w as ip\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "creating the data loader instance and setting batch size to 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoZH82hUuvEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_loader=torch.utils.data.DataLoader(trainset,batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2IKLHJrUWby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch= next(iter(data_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZnNN69aU8hN",
        "colab_type": "text"
      },
      "source": [
        "batch of 10 images is in the shape of [batch_size, ip channels, h,w]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4QjSx9BUd4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images, labels=batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32odaB6FUgWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63f2d7ba-f9b7-406c-d99e-efd4833babc6"
      },
      "source": [
        "images.shape #10 images with 1 color channel with 28*28 resolution"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG2Y5etwU0qi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c8f6ea3-94b3-42eb-bf34-d0ec2372a56e"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDl11gk3VN0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds=network(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL1kji44VRKJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b999a415-c9a6-48f9-bd95-9620a29395c9"
      },
      "source": [
        "preds.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peMMovVVVV5X",
        "colab_type": "text"
      },
      "source": [
        "as we have 10 images we have 10 prediction classes for 10 images so o/p size is 10*10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZXkCsbBVSaA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b84076de-32d4-4259-b57e-97c6ed02afef"
      },
      "source": [
        "preds.argmax(dim=1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm_YoEtzYTQ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58f7b3f1-7636-4d7a-a5f4-9ab3f39b0b64"
      },
      "source": [
        "labels\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U3hLlREY1qF",
        "colab_type": "text"
      },
      "source": [
        "lets try to find number of correct predictions\n",
        "\n",
        "\n",
        "> we will equate the number labels with pred.argmax, where there is a match between predictions and true match we should get one( fashion mnist dataset has a predefined order to labels and correcponding clothing)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfhgbiEFYWU8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f33e93c0-4523-4a96-eeae-ac734f03c90c"
      },
      "source": [
        "preds.argmax(dim=1).eq(labels)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h92nC1AfZUqb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e912793c-3142-4597-da24-6edc3db76b6d"
      },
      "source": [
        "preds.argmax(dim=1).eq(labels).sum() "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD5-G1UtZbCT",
        "colab_type": "text"
      },
      "source": [
        "so 2 predictions out of 10 were correct\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "now create a function which tells us the number of correct prediction when we give predictions and labels as ip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o-KAt_PZZK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_num_correct(preds, labels):\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj4b5EklZ03z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}