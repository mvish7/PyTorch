{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mvish7/PyTorch/blob/master/building_nn_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK1ABmF0Tf9H",
        "colab_type": "text"
      },
      "source": [
        "##video18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvvEca4FHFxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "#import torchvision.transform as transforms\n",
        "import torch.nn as nn\n",
        "import torch.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awkkqntsWiMo",
        "colab_type": "text"
      },
      "source": [
        "Creating a class with n/w structure , inheriting the nn.module class to use methods such as conv2d, linear for class creation.\n",
        "\n",
        "hint about super function: the super function can be used to gain access to inherited methods – from a parent or sibling class – that has been overwritten in a class object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj6Z7Gt_JSdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Network,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "    \n",
        "    self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "    self.out = nn.Linear(in_features=60, out_features=10)\n",
        "    \n",
        "  def fwd_pass(self,t):\n",
        "    #implementing fwd pass\n",
        "    return t\n",
        "  \n",
        "  def __repr__(self):\n",
        "    return \"liznet\"\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWM5cSnnTpNh",
        "colab_type": "text"
      },
      "source": [
        "## video 19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nAAo6qFX1qU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "network=Network()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bM7r52B5cQB",
        "colab_type": "code",
        "outputId": "c903938c-b7b0-4cbc-c442-3f1e49b4ac4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "print(network) #string representations of network class, which is inheriting the nn.Module class. So in all nn class in torch has a fun for string representation\n",
        "#this is how default print fun would print"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
            "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMuOq6Z66-t_",
        "colab_type": "text"
      },
      "source": [
        "overriding the print functionality inherited from the base(nn) class. sop that we can print what we want for our class. this can be done by \"def__repr__()\"\" func."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3OKifVl6Uvv",
        "colab_type": "code",
        "outputId": "42738772-0de2-4840-a318-937a8d584cd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(network) #this is how custom (overridden) print fun would print"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "liznet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKWpKx3u_PGq",
        "colab_type": "text"
      },
      "source": [
        "getting info about n/w layers by using  **\".\"'**  function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnBFda-O_OuV",
        "colab_type": "code",
        "outputId": "48efda53-dc31-4dec-9fb5-dad779646761",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "network.conv1 #this is nothing but string representation if a layer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-274Ucu8AG-",
        "colab_type": "code",
        "outputId": "6b8b9189-0b8c-431b-ddb5-e96872033b08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "network.fc1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=192, out_features=120, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6TVhHcv_29x",
        "colab_type": "text"
      },
      "source": [
        "now accessing the weights of the network (layerwise)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE3W_39t_lZC",
        "colab_type": "code",
        "outputId": "e7e024f5-0c39-48a6-c453-09a508c5ca90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "network.conv1.weight"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[[[ 0.0247, -0.1047,  0.0211,  0.1186, -0.0448],\n",
              "          [ 0.0138, -0.0093, -0.1188,  0.0391, -0.1347],\n",
              "          [ 0.0566,  0.1313, -0.1986,  0.0986, -0.1233],\n",
              "          [ 0.1525,  0.0465,  0.0133,  0.0536, -0.0031],\n",
              "          [-0.0864,  0.0019,  0.1104,  0.0089, -0.1869]]],\n",
              "\n",
              "\n",
              "        [[[-0.0633,  0.1059,  0.0411,  0.0690, -0.0698],\n",
              "          [-0.1135,  0.1928, -0.0204,  0.0375, -0.1929],\n",
              "          [-0.1801,  0.0349,  0.0122,  0.0779, -0.1760],\n",
              "          [-0.0889,  0.0721, -0.0967, -0.0626,  0.1486],\n",
              "          [ 0.0277,  0.1479,  0.0841, -0.1512,  0.1431]]],\n",
              "\n",
              "\n",
              "        [[[ 0.1870, -0.1043, -0.1414, -0.0851,  0.0129],\n",
              "          [ 0.0123, -0.1522,  0.0161, -0.0972,  0.1473],\n",
              "          [-0.1875, -0.1816, -0.1025,  0.0965, -0.0093],\n",
              "          [ 0.0801, -0.1427,  0.1103, -0.1236, -0.0462],\n",
              "          [-0.0632, -0.1241,  0.1784,  0.0051, -0.1093]]],\n",
              "\n",
              "\n",
              "        [[[ 0.1894,  0.1703, -0.0453, -0.1918, -0.1981],\n",
              "          [ 0.0072, -0.0535, -0.1580, -0.1554, -0.1292],\n",
              "          [-0.1251, -0.1200, -0.1247, -0.1125, -0.0982],\n",
              "          [-0.1435, -0.0953, -0.1142, -0.1634,  0.1089],\n",
              "          [ 0.1179, -0.1322,  0.1849,  0.0762, -0.1750]]],\n",
              "\n",
              "\n",
              "        [[[-0.1090,  0.1736, -0.0652,  0.1837,  0.0591],\n",
              "          [-0.0640,  0.0875,  0.1689, -0.0175, -0.1811],\n",
              "          [ 0.1768,  0.0165, -0.1284, -0.1358, -0.0646],\n",
              "          [ 0.1048, -0.0235,  0.0054, -0.1213, -0.0015],\n",
              "          [ 0.1222, -0.0615, -0.0407, -0.0848,  0.0395]]],\n",
              "\n",
              "\n",
              "        [[[-0.1910, -0.0561,  0.1661, -0.1536, -0.1139],\n",
              "          [-0.1304,  0.1556,  0.1689,  0.0733, -0.1944],\n",
              "          [ 0.1756, -0.1431, -0.0744, -0.1623,  0.0502],\n",
              "          [ 0.1647,  0.0581, -0.0098,  0.1310, -0.1224],\n",
              "          [ 0.0181,  0.0502, -0.0158,  0.0419,  0.0286]]]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-WQHYNtDer3",
        "colab_type": "text"
      },
      "source": [
        "torch has a class called parameter which extends a class called tensor, so weight tensor in each layer is a instance of parameter class. \n",
        "nn module class is looking for any attributes which are instances of parameter class, if it finds the instance of the parameter class and nn class keeps track of it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USIxPOSA_-dA",
        "colab_type": "code",
        "outputId": "263c73e1-d319-4294-a8b1-a57a47a7598e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "network.conv1.weight.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 1, 5, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFyX0TrvKVbw",
        "colab_type": "code",
        "outputId": "171eaf5c-e5d0-4afe-e1e7-89430281fdd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "network.conv2.weight.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12, 6, 5, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX_fb8pEKZiO",
        "colab_type": "code",
        "outputId": "512b139a-e8c7-4bdf-92b9-ec4d15f47b39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "network.conv1.weight[-1].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8OVxwo3P_j4",
        "colab_type": "text"
      },
      "source": [
        "accessing the weight of the linear layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NamSxPK8QjRj",
        "colab_type": "code",
        "outputId": "b2ede445-f4bf-4db3-d668-3beddbe7b06b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "network.fc1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=192, out_features=120, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7MCjTn6KiPz",
        "colab_type": "code",
        "outputId": "3295651c-b3ee-4d45-d625-52f571952048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "network.fc1.weight"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0275, -0.0297,  0.0547,  ...,  0.0345,  0.0057, -0.0504],\n",
              "        [ 0.0594,  0.0338, -0.0414,  ...,  0.0400,  0.0019, -0.0309],\n",
              "        [ 0.0016,  0.0205,  0.0054,  ...,  0.0142,  0.0371,  0.0022],\n",
              "        ...,\n",
              "        [ 0.0540,  0.0016,  0.0366,  ..., -0.0579,  0.0235,  0.0392],\n",
              "        [ 0.0447, -0.0204, -0.0264,  ...,  0.0133, -0.0216, -0.0174],\n",
              "        [ 0.0068, -0.0538,  0.0092,  ..., -0.0140, -0.0103,  0.0700]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3tDmP8KQVxk",
        "colab_type": "code",
        "outputId": "e442b090-d224-43a8-d590-d2d368140ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "network.fc1.weight.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([120, 192])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a0ZYdULTurt",
        "colab_type": "text"
      },
      "source": [
        "## video 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb_TRAxp7TWH",
        "colab_type": "text"
      },
      "source": [
        "lets see how linear layers maps the ip_features to op_features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I0NexfdQhTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "ip_features=torch.tensor([1,2,3,4], dtype=torch.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEV76oCQ7oHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight_matrix=torch.tensor([[1,2,3,4],\n",
        "                          [2,3,4,5],\n",
        "                          [3,4,5,6]], dtype=torch.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbnYiza774jc",
        "colab_type": "code",
        "outputId": "272da3db-0ba7-49e7-d60d-fae83d8b1f51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "weight_matrix.matmul(ip_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([30., 40., 50.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP9wkM9I8O0s",
        "colab_type": "text"
      },
      "source": [
        "creating the pytorch linear layer which does the same operation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZC6lqEa8Efb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fc=nn.Linear(in_features=4, out_features=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9ZPk9br9m2i",
        "colab_type": "text"
      },
      "source": [
        "now let's call the layer that we have made. we can call any layer like this cause torch nn layers are callable python modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55iY6d2m8opL",
        "colab_type": "code",
        "outputId": "eb653bd7-6527-4a74-ae31-1778e8f0e84a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fc(ip_features) #essentially we paseed a tensor as ip here. values of this operations differ from our above matmul why??\n",
        "#because TORCH CREATES A WEIGHT MATRIX AND INITIALIZES IT WITH RANDOM VALUES"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5680, 0.0325, 0.2372], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dYmc67V-V9B",
        "colab_type": "text"
      },
      "source": [
        "Now setting weight matrix same as we had previously\n",
        "**remember to wrap weight matrix in parameter class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CXDEXAK9zdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fc.weight=nn.Parameter(weight_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_J8iqiw_VAA",
        "colab_type": "text"
      },
      "source": [
        "now calling fc layer again with in_features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42QDiIHd-v3M",
        "colab_type": "code",
        "outputId": "4eea807b-3a0e-4502-bb26-b1922dd79bdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fc(ip_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([30.0059, 39.8449, 50.2667], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM0dw5wY_cTc",
        "colab_type": "text"
      },
      "source": [
        "now see output comes near to the original matmul but still somewhat not the same, why??\n",
        "**because of bias**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TA38w_OdDnC",
        "colab_type": "text"
      },
      "source": [
        "##video21 Implementing forward method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqaN8F9r_ZeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFyB4z6_dQrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Network,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "    \n",
        "    self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "    self.out = nn.Linear(in_features=60, out_features=10)\n",
        "    \n",
        "  def fwd_pass(self,t):\n",
        "    #implementing fwd pass\n",
        "    \n",
        "    # input layer\n",
        "    t=t #returning the tensor as it as, no need of processing\n",
        "    \n",
        "    # hidden layer 1 \n",
        "    t=self.conv1(t)\n",
        "    t=F.relu(t)\n",
        "    t=F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "    \n",
        "    \n",
        "    #hidden layer 2\n",
        "    t=self.conv2(t)\n",
        "    t=F.relu(t)\n",
        "    t=F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "    \n",
        "    #hidden layer 3\n",
        "    t=t.reshape(-1,12*4*4)  #doing the flattening operation before passing the tensor from conv layer to the linear layer\n",
        "    t=self.fc1(t)\n",
        "    t=F.relu(t)\n",
        "    \n",
        "    #hidden layer 4\n",
        "    t=self.fc2(t)\n",
        "    t=F.relu(t)\n",
        "    \n",
        "    #output layer\n",
        "    t=self.out(t)\n",
        "    #t=F.softmax(t, dim=1)  no need to use softmax here, coz we are using cross entropy as our loss function and it has built in softmax.\n",
        "    \n",
        "    \n",
        "    return t\n",
        "  \n",
        "  def __repr__(self):\n",
        "    return \"liznet\"\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPtKnA8ifb1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}